{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "In this section we will look at how to get our data into an appropriate format that we require. We will look at filtering, reshaping and aggregating data.\n",
    "\n",
    "This section will cover key functions:\n",
    "- Filtering data:  `iloc`, `query`\n",
    "- Adding and modifying columns: `rename`, `drop`, `split`\n",
    "- Reshaping data:  `pivot_table`, `melt`, `merge`, `concatenate`\n",
    "- Aggregating data: `groupby`\n",
    "- Row-wise operations: `apply`, `iterrows`\n",
    "\n",
    "## Filtering Data\n",
    "\n",
    "First we want to show how we can select certain columns. It is useful to know that if we just want to print the columns of a dataframe we can use built in `columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "data = pd.read_excel(Path.cwd() / \"data/Financial Sample.xlsx\", header =2)\n",
    "\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select certain columns based on their name or their positional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must use double square brackets when referencing more than 1 column\n",
    "data[[\"Segment\",\"Country\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referencing positional arguments this prints column 4 and 5\n",
    "data.iloc[:,3:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly you can use `iloc` for filtering rows where we have `.iloc[row_indexer, column_indexer]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the second row of data\n",
    "data.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives the last row of data\n",
    "data.iloc[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter rows based on certain conditions \n",
    "- Comparing values (`==`, `!=`, `>`, `<`, `>=`, `<=`)\n",
    "- Comparing variables (`is`, `is not`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"Discount Band\"] == \"High\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple conditions, each condition must be in brackets ()  - & is intersection operator, both conditions have to apply\n",
    "\n",
    "data[(data[\"Discounts\"] >= 10) & (data[\"Discounts\"] <= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | is union operator - either condition can apply\n",
    "\n",
    "data[(data[\"Country\"] == \"France\") | (data[\"Discounts\"] <= 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can use the `query` function to get the same result and can be easier to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('Country == \"France\" or Discounts <= 100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also filter based on a list of possible entries using the `isin` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_segments = [\"Government\",\"Enterprise\"]\n",
    "\n",
    "data[data[\"Segment\"].isin(special_segments)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and modifying columns\n",
    "\n",
    "You can simply add columns by stating it like you would access an exising column and equate it whatever you want this column to contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sale Price in 2025\"] = data[\"Sale Price\"] * 1.1\n",
    "\n",
    "print(data[[\"Sale Price\",\"Sale Price in 2025\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rename columns using the `rename` function and setting old column name and new column name out like a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"Segment\":\"Category\",\"Sale Price in 2025\":\"SALE PRICE\"})\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can remove whole columns using the `drop` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns={\"SALE PRICE\"})\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `rename` and `drop` include an argument `inplace` where `inplace=True` will alter the DataFrame in place, however it is better practice to reassign this DataFrame.\n",
    "\n",
    "You might also wish to split up a column for example you may wish to split the \"Date\" column into its separate componants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"Year\",\"Month\",\"Day\"]] = data[\"Date\"].astype(str).str.split(\"-\", expand=True)\n",
    "\n",
    "print(data[[\"Year\",\"Month\",\"Day\",\"Date\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may only want part of the split, you can do this by treating the split like a list of the different components, so to just get the year this is the first item in the list so index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Year\"] = data[\"Date\"].astype(str).str.split(\"-\", expand=True)[0]\n",
    "\n",
    "print(data[[\"Year\",\"Date\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping data\n",
    "\n",
    "### Pivot tables\n",
    "\n",
    "A pivot table is a really useful way to reshape and summarise data. You choose a column to be the index, this means each row will represent a unique entry from this column, then you pick another column to the columns, this means each columns will represent a unique entry from this column, then you choose the values, these will be entries of the table and this must be a numeric column. We can use pandas `pivot_table` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = data.pivot_table(index=\"Date\", columns=\"Country\", values=\"Units Sold\", aggfunc=\"sum\").reset_index()\n",
    "\n",
    "print(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melting (Unpivoting)\n",
    "\n",
    "Now suppose we the data so we have only one value on each row and every row is a unique combination of Date and Country. We can unpivot the table using the `melt` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unpivot = df_pivot.melt(id_vars=[\"Date\"])\n",
    "\n",
    "print(df_unpivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging DataFrames\n",
    "\n",
    "You can combine 2 DataFrames together based on 1 or more common keys using built in pandas function `merge`. With argument how you have the option of right, left, inner and outer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(Path.cwd() / \"data/Financial Sample.xlsx\", header =2)\n",
    "df2 = pd.read_csv(Path.cwd() / \"data/customers-1000.csv\")\n",
    "\n",
    "df_merged = pd.merge(df1, df2, on='Country', how='inner')\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating DataFrames\n",
    "\n",
    "If you want to combine 2 dataframes together that have the same columns by stacking one on top of the other, this is what the `concatenate` function is for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(Path.cwd() / \"data/customers-1000.csv\", usecols=[2,3])\n",
    "df3[\"variable\"] = \"A\"\n",
    "df4 = pd.read_csv(Path.cwd() / \"data/customers-1000.csv\", usecols=[2,3])\n",
    "df4[\"variable\"] = \"B\"\n",
    "\n",
    "df_concat = pd.concat([df3,df4], ignore_index=True)\n",
    "\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data\n",
    "\n",
    "Say you want to combine rows together and apply some sort of calculation to the rows you are combining such as sum or mean. You can group rows together using `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(Path.cwd() / \"data/Financial Sample.xlsx\", header =2, usecols=[1,4,7])\n",
    "\n",
    "df_grouped = data.groupby(['Country'])[\"Units Sold\"].sum()\n",
    "\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(Path.cwd() / \"data/Financial Sample.xlsx\", header =2, usecols=[1,4,7])\n",
    "\n",
    "df_grouped = data.groupby(['Country'])[\"Gross Sales\"].mean()\n",
    "\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row-Wise Operations\n",
    "\n",
    "We have considered vectorized operation where we can apply a function to the entire column of a dataframe at once. This is much more efficient and reduces computational costs but there are situations where you will need to apply functions a row at a time. This is where the `apply` function comes in very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to return the gross sales per unit\n",
    "def get_sales_per_unit(row):\n",
    "    return row['Gross Sales'] / row['Units Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales per unit'] = data.apply(get_sales_per_unit, axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to keep this more concise and you won't be using this function anywhere else, it is better to use a lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales per unit concise'] = data.apply(lambda row: row['Gross Sales'] / row['Units Sold'], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will also be scenarios were we want to iterate through rows of a dataframe using `iterrows` function. This allows you to iterate through index and row pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_categories = []\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in data.iterrows():\n",
    "    if row['Units Sold'] > 1000:\n",
    "        performance_categories.append('High')\n",
    "    elif 700 <= row['Units Sold'] <= 1000:\n",
    "        performance_categories.append('Medium')\n",
    "    else:\n",
    "        performance_categories.append('Low')\n",
    "\n",
    "# Add the new column to the DataFrame\n",
    "data['performance_category'] = performance_categories\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
